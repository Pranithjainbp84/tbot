{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Twitter with Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:02:33.419679Z",
     "start_time": "2020-10-22T22:02:33.417262Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import tweepy\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T21:37:14.273118Z",
     "start_time": "2020-10-22T21:37:14.270246Z"
    }
   },
   "outputs": [],
   "source": [
    "# twitter_keys = {\n",
    "#         'consumer_key':        '----INPUT KEYS HERE----',\n",
    "#         'consumer_secret':     '----INPUT KEYS HERE----',\n",
    "#         'access_token_key':    '----INPUT KEYS HERE----',\n",
    "#         'access_token_secret': '----INPUT KEYS HERE----'\n",
    "#     }\n",
    "\n",
    "\n",
    "#Setup access to API\n",
    "auth = tweepy.OAuthHandler(twitter_keys['consumer_key'], twitter_keys['consumer_secret'])\n",
    "auth.set_access_token(twitter_keys['access_token_key'], twitter_keys['access_token_secret'])\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current features in play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T21:37:14.277585Z",
     "start_time": "2020-10-22T21:37:14.275080Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['verified', \n",
    "            #'created_at',\n",
    "            'hour_created',\n",
    "            #'lang',\n",
    "            #'acct_location',\n",
    "            'geo_enabled', \n",
    "            'default_profile', \n",
    "            'default_profile_image', \n",
    "            'favourites_count', \n",
    "            'followers_count', \n",
    "            'friends_count', \n",
    "            'statuses_count', \n",
    "            'average_tweets_per_day',\n",
    "            #'avg_daily_followers', \n",
    "            #'avg_daily_friends',\n",
    "            #'avg_daily_favorites',\n",
    "            'popularity', \n",
    "            'tweet_to_followers', \n",
    "            'follower_acq_rate', \n",
    "            'friends_acq_rate', \n",
    "            #'favs_rate'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Scrape user info from Twitter handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T21:37:14.284056Z",
     "start_time": "2020-10-22T21:37:14.279399Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_user_info(screen_name):\n",
    "    '''\n",
    "    Input: a Twitter handle (screen_name)\n",
    "    Returns: a list of account-level information -- \n",
    "            [handle, created_at, account_age_days, verified, geo_enabled, lang, location, \n",
    "                default_profile, default_profile_image, favourites_count, followers_count, \n",
    "                friends_count, statuses_count, average_tweets_per_day]\n",
    "    '''\n",
    "    try:      \n",
    "        # Get user information from screen name\n",
    "        user = api.get_user(screen_name)\n",
    "        \n",
    "        # account attributes to return\n",
    "        handle = user.screen_name\n",
    "        created_at = user.created_at.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        account_age_days = (datetime.now() - user.created_at).days       \n",
    "        verified = user.verified\n",
    "        geo_enabled = user.geo_enabled\n",
    "        lang = user.lang\n",
    "        location = user.location\n",
    "        default_profile = user.default_profile\n",
    "        default_profile_image = user.default_profile_image\n",
    "        favourites_count = user.favourites_count\n",
    "        followers_count = user.followers_count\n",
    "        friends_count = user.friends_count\n",
    "        statuses_count = user.statuses_count\n",
    "        average_tweets_per_day = np.round(statuses_count / account_age_days, 3)\n",
    "        \n",
    "        # organizing list to be returned\n",
    "        account_info = [handle, created_at, account_age_days, verified, geo_enabled, lang, location, \n",
    "                        default_profile, default_profile_image, favourites_count, followers_count, \n",
    "                        friends_count, statuses_count, average_tweets_per_day]\n",
    "        \n",
    "    except BaseException as e:\n",
    "          print('failed on_status,',str(e))\n",
    "          time.sleep(3)\n",
    "    \n",
    "    return account_info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T21:37:14.287297Z",
     "start_time": "2020-10-22T21:37:14.285494Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#get_user_info('scrapfishies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape multiple users from a list into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T21:37:14.293188Z",
     "start_time": "2020-10-22T21:37:14.289817Z"
    }
   },
   "outputs": [],
   "source": [
    "def account_level_df(list_of_users):\n",
    "    '''\n",
    "    Input: a list of Twitter users (by handle or screen name)\n",
    "    Returns: a pandas dataframe of account-level details provided \n",
    "                using the get_user_info() function\n",
    "    '''\n",
    "    try: \n",
    "        # Scrape each account and compile into a list\n",
    "        accounts = [get_user_info(user) for user in list_of_users]\n",
    "        \n",
    "        # Assemble accounts list into a pandas dataframe\n",
    "        headers = ['handle', 'created_at', 'account_age_days', 'verified', 'geo_enabled', 'lang', 'location', \n",
    "                        'default_profile', 'default_profile_image', 'favourites_count', 'followers_count', \n",
    "                        'friends_count', 'statuses_count', 'average_tweets_per_day']   \n",
    "        \n",
    "        df = pd.DataFrame(accounts, columns=headers)\n",
    "    \n",
    "    except BaseException as e:\n",
    "          print('failed on_status,',str(e))\n",
    "          time.sleep(3)\n",
    "        \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T21:37:14.297186Z",
     "start_time": "2020-10-22T21:37:14.295417Z"
    }
   },
   "outputs": [],
   "source": [
    "#users = ['scrapfishies', 'aoc', 'FloridaMan_']\n",
    "\n",
    "#account_level_df(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T21:40:17.604441Z",
     "start_time": "2020-10-22T21:40:17.598860Z"
    }
   },
   "outputs": [],
   "source": [
    "### STILL IN PROGRESS\n",
    "\n",
    "def get_user_features(screen_name):\n",
    "    '''\n",
    "    Input: a Twitter handle (screen_name)\n",
    "    Returns: a list of account-level information used to make a prediction \n",
    "            whether the user is a bot or not\n",
    "    '''\n",
    "    try:      \n",
    "        # Get user information from screen name\n",
    "        user = api.get_user(screen_name)\n",
    "        \n",
    "        # account features to return for predicton\n",
    "        handle = user.screen_name\n",
    "        created_at = user.created_at.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        account_age_days = (datetime.now() - user.created_at).days       \n",
    "        verified = user.verified\n",
    "        geo_enabled = user.geo_enabled\n",
    "        lang = user.lang\n",
    "        location = user.location\n",
    "        default_profile = user.default_profile\n",
    "        default_profile_image = user.default_profile_image\n",
    "        favourites_count = user.favourites_count\n",
    "        followers_count = user.followers_count\n",
    "        friends_count = user.friends_count\n",
    "        statuses_count = user.statuses_count\n",
    "        average_tweets_per_day = np.round(statuses_count / account_age_days, 3)\n",
    "        \n",
    "        # manufactured features\n",
    "        hour_created = int(user.created_at.strftime('%H'))\n",
    "        popularity = np.round(np.log(1 + friends_count) * np.log(1 + followers_count), 3)\n",
    "        tweet_to_followers = np.round(np.log(1 + statuses_count) / np.log(1 + followers_count), 3)\n",
    "        follower_acq_rate = np.round(np.log(1 + (followers_count / account_age_days)), 3)\n",
    "        friends_acq_rate = np.round(np.log(1 + (friends_count / account_age_days)), 3)\n",
    "        \n",
    "        # organizing list to be returned\n",
    "        account_features = [verified, hour_created, geo_enabled, default_profile, default_profile_image, \n",
    "                           favourites_count, followers_count, friends_count, statuses_count, \n",
    "                           average_tweets_per_day, popularity, tweet_to_followers, follower_acq_rate, \n",
    "                           friends_acq_rate]\n",
    "        \n",
    "    except BaseException as e:\n",
    "          print('failed on_status,',str(e))\n",
    "          time.sleep(3)\n",
    "    \n",
    "    return account_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T21:37:14.307737Z",
     "start_time": "2020-10-22T21:37:14.305361Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['verified', \n",
    "            'hour_created',\n",
    "            'geo_enabled', \n",
    "            'default_profile', \n",
    "            'default_profile_image', \n",
    "            'favourites_count', \n",
    "            'followers_count', \n",
    "            'friends_count', \n",
    "            'statuses_count', \n",
    "            'average_tweets_per_day',\n",
    "            'popularity', \n",
    "            'tweet_to_followers', \n",
    "            'follower_acq_rate', \n",
    "            'friends_acq_rate', \n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T21:40:22.132748Z",
     "start_time": "2020-10-22T21:40:22.017831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[False, 14, False, True, False, 18, 2, 63, 14, 0.132, 4.569,\n",
       "         2.465, 0.019, 0.466]], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapfish = np.matrix(np.array(get_user_features('scrapfishies'), dtype='O'))\n",
    "scrapfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T21:39:32.445485Z",
     "start_time": "2020-10-22T21:39:32.247415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[False, '14', False, True, False, 18, 2, 63, 14, 0.132, 4.569,\n",
       "         2.465, 0.019, 0.466]], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapfish = np.matrix(np.array(get_user_features('scrapfishies'), dtype='O'))\n",
    "scrapfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T21:40:42.874628Z",
     "start_time": "2020-10-22T21:40:42.766131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.000e+00, 1.400e+01, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "         1.800e+01, 2.000e+00, 6.300e+01, 1.400e+01, 1.320e-01,\n",
       "         4.569e+00, 2.465e+00, 1.900e-02, 4.660e-01]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info = np.matrix(get_user_features('scrapfishies'))\n",
    "user_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T21:37:14.469623Z",
     "start_time": "2020-10-22T21:37:14.455036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T21:40:33.563142Z",
     "start_time": "2020-10-22T21:40:33.449493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " 14,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " 18,\n",
       " 2,\n",
       " 63,\n",
       " 14,\n",
       " 0.132,\n",
       " 4.569,\n",
       " 2.465,\n",
       " 0.019,\n",
       " 0.466]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_features('scrapfishies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:16:05.665233Z",
     "start_time": "2020-10-22T22:16:05.662321Z"
    }
   },
   "outputs": [],
   "source": [
    "def bot_or_not(twitter_handle):\n",
    "    \n",
    "    features = ['verified', 'hour_created', 'geo_enabled', 'default_profile', 'default_profile_image', \n",
    "            'favourites_count', 'followers_count', 'friends_count', 'statuses_count', 'average_tweets_per_day',\n",
    "            'popularity', 'tweet_to_followers', 'follower_acq_rate', 'friends_acq_rate']\n",
    "\n",
    "    user_df = pd.DataFrame(np.matrix(get_user_features(twitter_handle)), columns=features)\n",
    "    \n",
    "    prediction = xgb_model.predict(user_df)[0]\n",
    "    \n",
    "    return \"Bot\" if prediction == 1 else \"Not a bot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:19:04.100016Z",
     "start_time": "2020-10-22T22:19:04.097519Z"
    }
   },
   "outputs": [],
   "source": [
    "def bot_proba(twitter_handle):\n",
    "    \n",
    "    user = np.matrix(get_user_features(twitter_handle))\n",
    "    \n",
    "    proba = xgb_model.predict_proba(user)[:,1][0]\n",
    "    \n",
    "    print(f'Probability of being a bot: {proba*100:.2f}%')\n",
    "    \n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:32:48.216742Z",
     "start_time": "2020-10-22T22:32:48.098160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bot'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_or_not('best_in_dumbest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:32:51.202518Z",
     "start_time": "2020-10-22T22:32:51.085356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of being a bot: 97.96%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97964954"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_proba('best_in_dumbest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing model for predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:09:06.311989Z",
     "start_time": "2020-10-22T22:09:06.308912Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('model.pickle','rb') as read_file:\n",
    "    xgb_model = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:09:07.790284Z",
     "start_time": "2020-10-22T22:09:07.785592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0.05, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1.8, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
